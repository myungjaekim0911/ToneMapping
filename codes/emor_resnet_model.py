import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision.models import resnet18
import numpy as np
import imageio.v3 as iio
import os
import glob
import torch.nn.functional as F
# ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì§•ì„ ìœ„í•´ scikit-imageì˜ resize í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
from skimage.transform import resize 
import matplotlib.pyplot as plt
import sys

# ==============================================================================
# 0. EMoR ë°ì´í„° íŒŒì‹± ë° ë¡œë“œ (ì´ì „ ë²„ì „ê³¼ ë™ì¼)
# ==============================================================================

def parse_emor_data(file_path):
    """
    ì‚¬ìš©ìì˜ 'E =', 'f0 =', 'h(1) =', ..., 'h(25) =' í¬ë§·ì— ë§ê²Œ ë°ì´í„°ë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤.
    """
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"ì˜¤ë¥˜: EMoR ë°ì´í„° íŒŒì¼ '{file_path}'ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    with open(file_path, 'r') as f:
        # ì¤„ ëì˜ ê³µë°± ì œê±° ë° ì¤„ë°”ê¿ˆ ë¬¸ì ì •ê·œí™”
        lines = [line.strip().replace('\r', '') for line in f.readlines()] 

    # 1. ëª¨ë“  íƒœê·¸ì˜ ì‹œì‘ ì¤„ ì¸ë±ìŠ¤ë¥¼ ì°¾ìŠµë‹ˆë‹¤. (ë°ì´í„°ëŠ” ë‹¤ìŒ ì¤„ë¶€í„° ì‹œì‘)
    E_tag = 'E ='
    f0_tag = 'f0 ='
    
    # h(1) = ë¶€í„° h(25) = ê¹Œì§€ íƒœê·¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    h_tags = [f'h({i})=' for i in range(1, 26)]
    all_tags = [E_tag, f0_tag] + h_tags
    
    tag_indices = {}
    
    for i, line in enumerate(lines):
        for tag in all_tags:
            if line.startswith(tag):
                tag_indices[tag] = i + 1
                break

    # 2. í•„ìˆ˜ íƒœê·¸ 27ê°œ(E, f0, h(1) ~ h(25))ê°€ ëª¨ë‘ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
    if len(tag_indices) != 27:
        missing_tags = [tag for tag in all_tags if tag not in tag_indices]
        print(f"ì˜¤ë¥˜: ì´ 27ê°œì˜ íƒœê·¸ ì¤‘ {len(missing_tags)}ê°œê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {missing_tags[:5]}...", file=sys.stderr)
        raise ValueError("EMoR íŒŒì¼ì—ì„œ í•„ìˆ˜ íƒœê·¸ 27ê°œ ì¤‘ ì¼ë¶€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ í¬ë§·ì„ í™•ì¸í•˜ì‹­ì‹œì˜¤.")

    
    # 3. ë¼ì¸ ë¸”ë¡ì„ ì²˜ë¦¬í•˜ì—¬ ë„˜íŒŒì´ ë°°ì—´ë¡œ ë³€í™˜í•˜ëŠ” í—¬í¼ í•¨ìˆ˜
    def _process_lines(block_lines, count, tag_name=""):
        all_numbers = []
        for line in block_lines:
            if line:
                all_numbers.extend(line.split())

        data = np.float32(all_numbers[:count])
        
        if data.size < count:
            padded_data = np.zeros(count, dtype=np.float32)
            padded_data[:data.size] = data
            return padded_data
        
        return data

    
    # 4. Eì™€ f0 ë°ì´í„° ì¶”ì¶œ (1000ê°œ ìƒ˜í”Œ)
    E_start = tag_indices[E_tag]
    E_end = tag_indices[f0_tag] - 1
    E = _process_lines(lines[E_start:E_end], 1000, tag_name='E')

    f0_start = tag_indices[f0_tag]
    f0_end = tag_indices[h_tags[0]] - 1
    f0 = _process_lines(lines[f0_start:f0_end], 1000, tag_name='f0')


    # 5. H í–‰ë ¬ ì¶”ì¶œ ë° ê²°í•© (1000 x 25)
    H_components = []
    
    for k in range(25):
        current_tag = h_tags[k]
        
        if k < 24:
            next_tag = h_tags[k+1]
            H_end_idx = tag_indices[next_tag] - 1
        else:
            H_end_idx = len(lines)
            
        H_start_idx = tag_indices[current_tag]
        
        h_k = _process_lines(lines[H_start_idx:H_end_idx], 1000, tag_name=current_tag)
        H_components.append(h_k)
        
    H = np.stack(H_components, axis=1) 
    print(f"H í–‰ë ¬ (PCA Basis) íŒŒì‹± ì™„ë£Œ. í¬ê¸°: {H.shape}")

    return torch.from_numpy(E).float(), torch.from_numpy(f0).float(), torch.from_numpy(H).float()

# ==============================================================================
# 1. ë¯¸ë¶„ ê°€ëŠ¥í•œ TMO Layer (CRF Reconstruction) - ì´ì „ ë²„ì „ê³¼ ë™ì¼
# ==============================================================================

class DifferentiableTMO(nn.Module):
    def __init__(self, E_samples, f0_mean, H_basis):
        super().__init__()
        self.register_buffer('E_samples', E_samples) # (1000,)
        self.register_buffer('f0_mean', f0_mean)     # (1000,)
        self.register_buffer('H_basis', H_basis)     # (1000, 25)

    def forward(self, hdr_image, weights_w):
        
        B, C, H, W = hdr_image.shape
        
        # 1. CRF ê³¡ì„  ìƒì„± (CRF = f0 + H * w)
        curve_delta = torch.matmul(self.H_basis, weights_w.T).T 
        CRF_curve = self.f0_mean + curve_delta # [B, 1000]
        
        # 2. í”½ì…€ ë§¤í•‘ (ë³´ê°„)
        sdr_output = torch.zeros_like(hdr_image)
        
        for i in range(B):
            for c in range(C):
                sdr_output[i, c, :, :] = self._interp_placeholder(
                    hdr_image[i, c, :, :],   # X_in: HDR í”½ì…€ ê°’
                    self.E_samples,          # X_points: EMoR E samples
                    CRF_curve[i]             # Y_points: CRF curve
                )
        
        return torch.clamp(sdr_output, 0.0, 1.0)
    
    def _interp_placeholder(self, x_in, x_points, y_points):
        # ê²½ê³ ë¥¼ ë°œìƒì‹œí‚¤ëŠ” ë¯¸ë¶„ ë¶ˆê°€ëŠ¥í•œ np.interp ì‚¬ìš©
        return torch.from_numpy(np.interp(x_in.detach().cpu().numpy(), 
                                          x_points.detach().cpu().numpy(), 
                                          y_points.detach().cpu().numpy()
                                         )).to(x_in.device).float()


# ==============================================================================
# 2. ResNet ê¸°ë°˜ PCA Weight Predictor - ì´ì „ ë²„ì „ê³¼ ë™ì¼
# ==============================================================================

class ResNetEMoR(nn.Module):
    def __init__(self, E_samples, f0_mean, H_basis, output_weights=25):
        super().__init__()
        
        self.resnet = resnet18(weights=None)
        self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)
        
        num_ftrs = self.resnet.fc.in_features
        self.resnet.fc = nn.Linear(num_ftrs, output_weights)
        
        self.tmo_layer = DifferentiableTMO(E_samples, f0_mean, H_basis)

    def forward(self, hdr_luminance_input, hdr_rgb_full):
        weights_w = self.resnet(hdr_luminance_input) # [B, 25]
        sdr_output = self.tmo_layer(hdr_rgb_full, weights_w) # [B, 3, H, W]
        return sdr_output, weights_w

# ==============================================================================
# 3. ë°ì´í„°ì…‹ ë° ì „ì²˜ë¦¬ - ì´ì „ ë²„ì „ê³¼ ë™ì¼
# ==============================================================================

class HDRLDRDataset(Dataset):
    def __init__(self, hdr_dir, ldr_dir, target_size=(256, 256), full_size=(1024, 1024)):
        self.hdr_dir = hdr_dir
        self.ldr_dir = ldr_dir
        self.target_size = target_size
        self.full_size = full_size
        
        hdr_files = sorted(glob.glob(os.path.join(self.hdr_dir, 'HDR_*.hdr')))
        self.file_indices = [os.path.basename(f).split('_')[1].split('.')[0] for f in hdr_files]
        
        assert len(self.file_indices) > 0, f"ì˜¤ë¥˜: HDR ë””ë ‰í† ë¦¬ì—ì„œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œ: {hdr_dir}"
        print(f"ì´ {len(self.file_indices)} ìŒì˜ ì´ë¯¸ì§€ ì¸ë±ìŠ¤ ë¡œë“œ ì¤€ë¹„ ì™„ë£Œ.")


    def __len__(self):
        return len(self.file_indices)

    def __getitem__(self, idx):
        file_index = self.file_indices[idx]
        
        hdr_path = os.path.join(self.hdr_dir, f'HDR_{file_index}.hdr')
        ldr_path = os.path.join(self.ldr_dir, f'LDR_{file_index}.jpg')
        
        hdr_rgb_full = iio.imread(hdr_path).astype(np.float32)
        ldr_gt_full = iio.imread(ldr_path).astype(np.float32) / 255.0
        
        # íœ˜ë„ ì¶”ì¶œ ë° ë‹¤ìš´ìƒ˜í”Œë§
        L_hdr_full = 0.2126 * hdr_rgb_full[..., 0] + 0.7152 * hdr_rgb_full[..., 1] + 0.0722 * hdr_rgb_full[..., 2]
        L_hdr_downsampled = resize(L_hdr_full, self.target_size, 
                                   anti_aliasing=True, preserve_range=True).astype(np.float32)
        
        # ë¡œê·¸ ë³€í™˜ ë° ì •ê·œí™”
        L_hdr_input = np.log(L_hdr_downsampled + 1e-5)
        L_hdr_input = (L_hdr_input - L_hdr_input.mean()) / (L_hdr_input.std() + 1e-5)
        
        L_hdr_input = torch.from_numpy(L_hdr_input).unsqueeze(0)
        hdr_rgb_full_tensor = torch.from_numpy(hdr_rgb_full).permute(2, 0, 1)
        ldr_gt_full_tensor = torch.from_numpy(ldr_gt_full).permute(2, 0, 1)
        
        return L_hdr_input.float(), hdr_rgb_full_tensor.float(), ldr_gt_full_tensor.float()


# ==============================================================================
# 5. í‰ê°€ ì§€í‘œ í•¨ìˆ˜ (TMQI Proxy)
# ==============================================================================

def calculate_tmqi_proxy(sdr_pred, ldr_gt_full):
    """
    TMQIì˜ êµ¬ì¡°ì  í’ˆì§ˆ(S)ì„ ê·¼ì‚¬í•˜ê¸° ìœ„í•´ ë¡œê·¸ íœ˜ë„ ë„ë©”ì¸ì—ì„œ MSEë¥¼ ì‚¬ìš©í•˜ì—¬
    TMQI í”„ë¡ì‹œ ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. (ì ìˆ˜ëŠ” 0~1, 1ì´ ìµœì )
    """
    
    def get_luminance(img_tensor): # [B, 3, H, W]
        # Rec. 709 íœ˜ë„ ê³µì‹: 0.2126R + 0.7152G + 0.0722B
        R, G, B = img_tensor.unbind(1)
        L = 0.2126 * R + 0.7152 * G + 0.0722 * B
        return L.unsqueeze(1) # [B, 1, H, W]

    L_pred = get_luminance(sdr_pred)
    L_gt = get_luminance(ldr_gt_full)
    
    eps = 1e-5
    
    # ë¡œê·¸ ë³€í™˜
    Log_L_pred = torch.log(L_pred + eps)
    Log_L_gt = torch.log(L_gt + eps)
    
    # êµ¬ì¡°ì  ì†ì‹¤(MSE)
    loss_S = F.mse_loss(Log_L_pred, Log_L_gt)
    
    # TMQI ìŠ¤ì½”ì–´ ë³€í™˜: Score = exp(-k * Loss) (ì ìˆ˜ë¥¼ 0~1 ë²”ìœ„ë¡œ ë§¤í•‘)
    # k=10ì„ ì‚¬ìš©í•˜ì—¬ ì‘ì€ ì†ì‹¤ì„ ì ìˆ˜ë¡œ ë³€í™˜
    S_score = torch.exp(-10 * loss_S) 
    
    # Naturalness (N) componentëŠ” ë³µì¡í•˜ë¯€ë¡œ ìƒëµí•˜ê³  S_scoreë§Œ ë°˜í™˜
    return S_score.mean().item()


def evaluate_model(model, val_loader, device, val_size):
    model.eval()
    val_loss = 0.0
    val_tmqi_total = 0.0
    
    with torch.no_grad():
        for L_hdr_input, hdr_rgb_full, ldr_gt_full in val_loader:
            L_hdr_input, hdr_rgb_full, ldr_gt_full = L_hdr_input.to(device), hdr_rgb_full.to(device), ldr_gt_full.to(device)
            
            sdr_pred, weights_w = model(L_hdr_input, hdr_rgb_full)
            
            loss_recon = nn.L1Loss()(sdr_pred, ldr_gt_full)
            val_loss += loss_recon.item() * L_hdr_input.size(0)
            
            # TMQI ê³„ì‚°
            val_tmqi_total += calculate_tmqi_proxy(sdr_pred, ldr_gt_full) * L_hdr_input.size(0)

    avg_val_loss = val_loss / val_size
    avg_val_tmqi = val_tmqi_total / val_size
    print(f"  Validation L1 Loss: {avg_val_loss:.6f}, TMQI Score: {avg_val_tmqi:.6f}")
    
    model.train()
    return avg_val_loss, avg_val_tmqi

# ==============================================================================
# 6. í•™ìŠµëœ EMoR Curve ë° ì§€í‘œ ì¶”ì´ ì‹œê°í™” í•¨ìˆ˜ (ìˆ˜ì •ë¨)
# ==============================================================================

def plot_results(model, val_loader, E_samples, f0_mean, H_basis, device, loss_history, tmqi_history):
    """
    1. í•™ìŠµëœ EMoR Curveë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤.
    2. í•™ìŠµ/ê²€ì¦ ì§€í‘œ(L1 Loss, TMQI) ì¶”ì´ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤.
    """
    # ------------------ 1. EMoR Curve ì‹œê°í™” ------------------
    model.eval()
    L_hdr_input, hdr_rgb_full, _ = next(iter(val_loader))
    L_hdr_input, hdr_rgb_full = L_hdr_input.to(device), hdr_rgb_full.to(device)
    
    with torch.no_grad():
        _, weights_w = model(L_hdr_input[0].unsqueeze(0), hdr_rgb_full[0].unsqueeze(0)) 

    w_vector = weights_w.squeeze(0).cpu().numpy()
    E_numpy = E_samples.cpu().numpy()
    f0_numpy = f0_mean.cpu().numpy()
    H_numpy = H_basis.cpu().numpy()

    curve_residual = H_numpy.dot(w_vector)
    final_crf_curve = f0_numpy + curve_residual

    plt.figure(figsize=(18, 6))
    
    # 1-1. EMoR Curve
    plt.subplot(1, 2, 1)
    plt.plot(E_numpy, final_crf_curve, label='Learned Tone Mapping Curve', color='red', linewidth=3)
    plt.plot(E_numpy, f0_numpy, '--', label='EMoR Mean Curve ($\mathbf{f}_0$)', color='gray', alpha=0.7)
    plt.xlabel('Scene Linear Radiance')
    plt.ylabel('LDR Pixel Value')
    plt.title('Learned EMoR Tone Mapping Curve (from a Single Validation Image)')
    plt.grid(True)
    plt.legend()
    
    # ------------------ 2. ì§€í‘œ ì¶”ì´ ì‹œê°í™” ------------------
    epochs = range(1, len(loss_history) + 1)
    
    # 1-2. Loss ë° TMQI ì¶”ì´
    plt.subplot(1, 2, 2)
    
    # Loss Plot
    line1, = plt.plot(epochs, loss_history, 
                      label='Validation L1 Loss (Minimize)', # <--- ë¼ë²¨ ìˆ˜ì •
                      color='blue', marker='o', linestyle='-')
    
    # TMQI Plot (TMQIëŠ” ê°’ì´ í´ìˆ˜ë¡ ì¢‹ìœ¼ë¯€ë¡œ ì˜¤ë¥¸ìª½ Yì¶• ì‚¬ìš©)
    ax2 = plt.gca().twinx()
    line2, = ax2.plot(epochs, tmqi_history, 
                       label='Validation TMQI Score (Maximize)', # <--- ë¼ë²¨ ìˆ˜ì •
                       color='green', marker='x', linestyle='--')
    
    plt.xlabel('Epoch')
    
    # Yì¶• ë¼ë²¨ì€ ê·¸ëŒ€ë¡œ ìœ ì§€ (ax2ì˜ ì¤‘ë³µ ë¼ë²¨ ì„¤ì •ì€ ì œê±°)
    plt.ylabel('Validation L1 Loss (Minimize)', color='blue')
    ax2.set_ylabel('Validation TMQI Score (Maximize)', color='green') # ax2ì— ëŒ€í•œ ë¼ë²¨ë§Œ ì„¤ì •

    plt.title('Validation Metrics Over Epochs')
    plt.grid(True, linestyle=':', alpha=0.6)
    
    # === í†µí•©ëœ ë²”ë¡€ ìƒì„± ë° ì˜¤ë¥¸ìª½ ìœ„ì— ìœ„ì¹˜ì‹œí‚¤ê¸° ===
    # ë‘ í”Œë¡¯ ê°ì²´(line1, line2)ì™€ ë¼ë²¨ì„ í†µí•©í•˜ì—¬ í•˜ë‚˜ì˜ ë²”ë¡€ë¥¼ ìƒì„±
    lines = [line1, line2]
    labels = [l.get_label() for l in lines]
    
    # ì˜¤ë¥¸ìª½ ìƒë‹¨ì— í†µí•© ë²”ë¡€ í‘œì‹œ
    plt.legend(lines, labels, loc='upper right') 
    
    # ê¸°ì¡´ì˜ ë¶„ë¦¬ëœ ë²”ë¡€ í˜¸ì¶œì€ ì œê±°í•©ë‹ˆë‹¤.
    # plt.legend(loc='upper left') 
    # ax2.legend(loc='upper right')
    
    plt.tight_layout()
    plt.show()
    
    model.train()

# ==============================================================================
# 4. í•™ìŠµ ì„¤ì • ë° ì‹¤í–‰ (ìˆ˜ì •ë¨)
# ==============================================================================

# ğŸš¨ ì‚¬ìš©ì ì§€ì • í•„ìˆ˜ ğŸš¨: LDR-HDR-pair_Dataset í´ë”ì˜ ìƒìœ„ ê²½ë¡œì™€ EMoR íŒŒì¼ ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.
DATASET_ROOT = os.path.expanduser('~/TM/') 
EMOR_DATA_PATH = os.path.abspath(os.path.join(os.path.dirname(os.path.abspath(__file__)) if '__file__' in locals() else os.getcwd(), '../dataset/emorCurves.txt'))

def train_model():
    HDR_DIR = os.path.join(DATASET_ROOT, 'LDR-HDR-pair_Dataset', 'HDR')
    LDR_DIR = os.path.join(DATASET_ROOT, 'LDR-HDR-pair_Dataset', 'LDR_exposure_0')
    
    print(f"--- ë°ì´í„° ê²½ë¡œ í™•ì¸ ---")
    print(f"HDR ë””ë ‰í† ë¦¬: {HDR_DIR}")
    print(f"LDR ë””ë ‰í† ë¦¬: {LDR_DIR}")
    print(f"EMoR íŒŒì¼: {EMOR_DATA_PATH}")
    print(f"------------------------")
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ì‚¬ìš© ì¥ì¹˜: {device}")
    
    # 1. EMoR ë°ì´í„° ë¡œë“œ
    try:
        E_samples, f0_mean, H_basis = parse_emor_data(EMOR_DATA_PATH)
    except FileNotFoundError as e:
        print(f"\nFATAL ERROR: EMoR ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”: {e}")
        return
    
    E_samples, f0_mean, H_basis = E_samples.to(device), f0_mean.to(device), H_basis.to(device)
    print(f"EMoR ë°ì´í„° ë¡œë“œ ì™„ë£Œ. H_basis.shape: {H_basis.shape}")

    # 2. ëª¨ë¸ ì´ˆê¸°í™”
    model = ResNetEMoR(E_samples, f0_mean, H_basis).to(device)
    
    # 3. ë°ì´í„° ë¡œë”
    full_dataset = HDRLDRDataset(HDR_DIR, LDR_DIR)
    total_samples = len(full_dataset)
    train_size = int(0.8 * total_samples)
    val_size = total_samples - train_size
    train_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size])
    
    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=2)
    val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=2)
    
    print(f"ë°ì´í„°ì…‹ ë¶„í• : í•™ìŠµ {train_size}ê°œ, ê²€ì¦ {val_size}ê°œ")
    
    # 4. ì†ì‹¤ í•¨ìˆ˜ ë° ìµœì í™”
    criterion_recon = nn.L1Loss() 
    optimizer = optim.Adam(model.parameters(), lr=1e-6)
    lambda_reg = 1e-5
    
    # 5. ì§€í‘œ ì €ì¥ ë¦¬ìŠ¤íŠ¸
    val_loss_history = []
    val_tmqi_history = []

    # 6. í•™ìŠµ ë£¨í”„
    num_epochs = 50
    for epoch in range(num_epochs):
        model.train()
        running_loss = 0.0
        
        for i, (L_hdr_input, hdr_rgb_full, ldr_gt_full) in enumerate(train_loader):
            L_hdr_input, hdr_rgb_full, ldr_gt_full = L_hdr_input.to(device), hdr_rgb_full.to(device), ldr_gt_full.to(device)
            
            optimizer.zero_grad()
            
            sdr_pred, weights_w = model(L_hdr_input, hdr_rgb_full)
            
            loss_recon = criterion_recon(sdr_pred, ldr_gt_full)
            loss_reg = torch.mean(weights_w.pow(2))
            
            loss = loss_recon + lambda_reg * loss_reg
            
            loss.backward()
            optimizer.step()
            
            running_loss += loss.item() * L_hdr_input.size(0)
            
        epoch_loss = running_loss / train_size
        print(f"Epoch {epoch+1}/{num_epochs}, Train Loss: {epoch_loss:.6f} (Recon: {loss_recon.item():.6f}, Reg: {loss_reg.item():.6f})")
        
        # 7. ê²€ì¦ ë° ì§€í‘œ ì €ì¥
        avg_val_loss, avg_val_tmqi = evaluate_model(model, val_loader, device, val_size)
        val_loss_history.append(avg_val_loss)
        val_tmqi_history.append(avg_val_tmqi)

    # 8. í•™ìŠµ ì™„ë£Œ í›„, EMoR Curve ë° ì§€í‘œ ì¶”ì´ ì‹œê°í™”
    print("\n--- í•™ìŠµ ì™„ë£Œ. EMoR Curve ë° ì§€í‘œ ì¶”ì´ ì‹œê°í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤ ---")
    plot_results(model, val_loader, E_samples, f0_mean, H_basis, device, val_loss_history, val_tmqi_history)


if __name__ == '__main__':
    train_model()