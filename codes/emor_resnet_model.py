import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision.models import resnet18
import numpy as np
import imageio.v3 as iio
import os
import glob
import torch.nn.functional as F
# ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì§•ì„ ìœ„í•´ scikit-imageì˜ resize í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
from skimage.transform import resize 

# ==============================================================================
# 0. EMoR ë°ì´í„° íŒŒì‹± ë° ë¡œë“œ (ì‚¬ìš©ì íŒŒì¼ í¬ë§·ì— ë§ê²Œ ìµœì¢… ìˆ˜ì •)
# ==============================================================================

def parse_emor_data(file_path):
    """
    ì‚¬ìš©ìì˜ 'E =', 'f0 =', 'h(1) =', ..., 'h(25) =' í¬ë§·ì— ë§ê²Œ ë°ì´í„°ë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤.
    """
    import os
    import numpy as np
    import torch
    import sys

    if not os.path.exists(file_path):
        raise FileNotFoundError(f"ì˜¤ë¥˜: EMoR ë°ì´í„° íŒŒì¼ '{file_path}'ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    with open(file_path, 'r') as f:
        # ì¤„ ëì˜ ê³µë°± ì œê±° ë° ì¤„ë°”ê¿ˆ ë¬¸ì ì •ê·œí™”
        lines = [line.strip().replace('\r', '') for line in f.readlines()] 

    # 1. ëª¨ë“  íƒœê·¸ì˜ ì‹œì‘ ì¤„ ì¸ë±ìŠ¤ë¥¼ ì°¾ìŠµë‹ˆë‹¤. (ë°ì´í„°ëŠ” ë‹¤ìŒ ì¤„ë¶€í„° ì‹œì‘)
    E_tag = 'E ='
    f0_tag = 'f0 ='
    
    # h(1) = ë¶€í„° h(25) = ê¹Œì§€ íƒœê·¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    h_tags = [f'h({i})=' for i in range(1, 26)]
    all_tags = [E_tag, f0_tag] + h_tags
    
    tag_indices = {}
    
    for i, line in enumerate(lines):
        for tag in all_tags:
            if line.startswith(tag):
                tag_indices[tag] = i + 1
                break # í•œ ì¤„ì— ì—¬ëŸ¬ íƒœê·¸ê°€ ìˆì„ ìˆ˜ ì—†ìœ¼ë¯€ë¡œ, ì°¾ìœ¼ë©´ ë‹¤ìŒ ì¤„ë¡œ ì´ë™

    # 2. í•„ìˆ˜ íƒœê·¸ 27ê°œ(E, f0, h(1) ~ h(25))ê°€ ëª¨ë‘ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
    if len(tag_indices) != 27:
        missing_tags = [tag for tag in all_tags if tag not in tag_indices]
        print(f"ì˜¤ë¥˜: ì´ 27ê°œì˜ íƒœê·¸ ì¤‘ {len(missing_tags)}ê°œê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {missing_tags[:5]}...", file=sys.stderr)
        raise ValueError("EMoR íŒŒì¼ì—ì„œ í•„ìˆ˜ íƒœê·¸ 27ê°œ ì¤‘ ì¼ë¶€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ í¬ë§·ì„ í™•ì¸í•˜ì‹­ì‹œì˜¤.")

    
    # 3. ë¼ì¸ ë¸”ë¡ì„ ì²˜ë¦¬í•˜ì—¬ ë„˜íŒŒì´ ë°°ì—´ë¡œ ë³€í™˜í•˜ëŠ” í—¬í¼ í•¨ìˆ˜
    def _process_lines(block_lines, count, tag_name=""):
        all_numbers = []
        for line in block_lines:
            if line: # ë¹ˆ ì¤„ì´ ì•„ë‹ˆë©´
                all_numbers.extend(line.split())

        # ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ë¥¼ float ë„˜íŒŒì´ ë°°ì—´ë¡œ ë³€í™˜
        data = np.float32(all_numbers[:count])
        
        if data.size < count:
            print(f"ê²½ê³ : {tag_name} ë°ì´í„° í¬ê¸°ê°€ ì˜ˆìƒì¹˜({count})ë³´ë‹¤ ì‘ìŠµë‹ˆë‹¤. ì‹¤ì œ í¬ê¸°: {data.size}", file=sys.stderr)
            # ë°ì´í„°ê°€ ë¶€ì¡±í•˜ë©´ ë¶€ì¡±í•œ ë§Œí¼ 0ìœ¼ë¡œ ì±„ì›Œì„œ ë°˜í™˜ (í•™ìŠµ ì§„í–‰ì„ ìœ„í•´)
            padded_data = np.zeros(count, dtype=np.float32)
            padded_data[:data.size] = data
            return padded_data
        
        return data

    
    # 4. Eì™€ f0 ë°ì´í„° ì¶”ì¶œ (1000ê°œ ìƒ˜í”Œ)
    E_start = tag_indices[E_tag]
    E_end = tag_indices[f0_tag] - 1
    E = _process_lines(lines[E_start:E_end], 1000, tag_name='E')

    f0_start = tag_indices[f0_tag]
    f0_end = tag_indices[h_tags[0]] - 1
    f0 = _process_lines(lines[f0_start:f0_end], 1000, tag_name='f0')


    # 5. H í–‰ë ¬ ì¶”ì¶œ ë° ê²°í•© (1000 x 25)
    H_components = []
    
    for k in range(25):
        current_tag = h_tags[k]
        
        # ë‹¤ìŒ íƒœê·¸ì˜ ì‹œì‘ ì¸ë±ìŠ¤ë¥¼ ì°¾ìŠµë‹ˆë‹¤. (k=24ì¼ ë•ŒëŠ” íŒŒì¼ ë ì‚¬ìš©)
        if k < 24:
            next_tag = h_tags[k+1]
            H_end_idx = tag_indices[next_tag] - 1
        else:
            H_end_idx = len(lines)
            
        H_start_idx = tag_indices[current_tag]
        
        # h(k) ë°ì´í„° (1000ê°œ ìƒ˜í”Œ) ì¶”ì¶œ
        h_k = _process_lines(lines[H_start_idx:H_end_idx], 1000, tag_name=current_tag)
        H_components.append(h_k)
        
    # 25ê°œì˜ (1000,) ë²¡í„°ë¥¼ (1000, 25) í–‰ë ¬ë¡œ ê²°í•© (25ê°œì˜ ì—´)
    H = np.stack(H_components, axis=1) 
    print(f"H í–‰ë ¬ (PCA Basis) íŒŒì‹± ì™„ë£Œ. í¬ê¸°: {H.shape}")

    # 6. Tensor ë°˜í™˜
    return torch.from_numpy(E).float(), torch.from_numpy(f0).float(), torch.from_numpy(H).float()

# ==============================================================================
# 1. ë¯¸ë¶„ ê°€ëŠ¥í•œ TMO Layer (CRF Reconstruction)
# ==============================================================================

class DifferentiableTMO(nn.Module):
    def __init__(self, E_samples, f0_mean, H_basis):
        super().__init__()
        self.register_buffer('E_samples', E_samples) # (1000,)
        self.register_buffer('f0_mean', f0_mean)     # (1000,)
        self.register_buffer('H_basis', H_basis)     # (1000, 25)

    def forward(self, hdr_image, weights_w):
        # hdr_image: [B, 3, H, W] (ì›ë³¸ ê³ í•´ìƒë„ HDR RGB)
        # weights_w: [B, 25] (PCA ê°€ì¤‘ì¹˜)
        
        B, C, H, W = hdr_image.shape
        
        # 1. CRF ê³¡ì„  ìƒì„± (CRF = f0 + H * w)
        # H_basis: [1000, 25]
        # weights_w.T: [25, B]
        # Matmul ê²°ê³¼: [1000, B]. Transposeí•˜ì—¬ [B, 1000]
        curve_delta = torch.matmul(self.H_basis, weights_w.T).T 
        
        # [B, 1000] + [1000] (f0_mean) -> ë¸Œë¡œë“œìºìŠ¤íŠ¸
        CRF_curve = self.f0_mean + curve_delta # [B, 1000]
        
        # 2. í”½ì…€ ë§¤í•‘ (ë³´ê°„)
        sdr_output = torch.zeros_like(hdr_image)
        
        # ê° ë°°ì¹˜ ë° ì±„ë„ì— ëŒ€í•´ CRF ë³´ê°„ ì ìš©
        for i in range(B):
            for c in range(C):
                # (PLACEHOLDER: Differentiable Interpolation Logic)
                # **ì£¼ì˜**: ì´ ë¶€ë¶„ì€ np.interpë¥¼ ì‚¬ìš©í•˜ì—¬ ë¯¸ë¶„ ë¶ˆê°€ëŠ¥í•˜ë©°, 
                # í•™ìŠµ ì‹œ ê²½ê³ ê°€ ë°œìƒí•©ë‹ˆë‹¤. ì‹¤ì œë¡œëŠ” PyTorchì˜ Differentiable 
                # Look-Up Table (LUT) ë˜ëŠ” Autograd Functionìœ¼ë¡œ ëŒ€ì²´ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
                
                sdr_output[i, c, :, :] = self._interp_placeholder(
                    hdr_image[i, c, :, :],   # X_in: HDR í”½ì…€ ê°’
                    self.E_samples,          # X_points: EMoR E samples
                    CRF_curve[i]             # Y_points: CRF curve
                )
        
        return torch.clamp(sdr_output, 0.0, 1.0)
    
    def _interp_placeholder(self, x_in, x_points, y_points):
        # np.interpëŠ” ë¯¸ë¶„ ê·¸ë˜í”„ë¥¼ ëŠìœ¼ë¯€ë¡œ, detach() í›„ numpy ì—°ì‚° ìˆ˜í–‰
        # í•™ìŠµì„ ìœ„í•œ ê°œë… ì½”ë“œì´ë¯€ë¡œ ì´ëŒ€ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.
        
        # TMO ì ìš© ì „ ì „ì—­ ìŠ¤ì¼€ì¼ë§ (Log-Avg Luminance ê¸°ë°˜)ì´ í•„ìš”í•˜ì§€ë§Œ, 
        # ì´ëŠ” TMO ì•Œê³ ë¦¬ì¦˜ì˜ ì¼ë¶€ì´ë¯€ë¡œ, ì—¬ê¸°ì„œëŠ” EMoRì˜ E_samplesì— ì´ë¯¸ 
        # ì •ê·œí™”ëœ ê°’ì´ ì…ë ¥ëœë‹¤ê³  ê°€ì •í•˜ê³  ì§„í–‰í•©ë‹ˆë‹¤. (Mean EMoR TMO ë¡œì§ ìƒëµ)
        
        return torch.from_numpy(np.interp(x_in.detach().cpu().numpy(), 
                                          x_points.detach().cpu().numpy(), 
                                          y_points.detach().cpu().numpy()
                                         )).to(x_in.device).float()


# ==============================================================================
# 2. ResNet ê¸°ë°˜ PCA Weight Predictor
# ==============================================================================

class ResNetEMoR(nn.Module):
    def __init__(self, E_samples, f0_mean, H_basis, output_weights=25):
        super().__init__()
        
        self.resnet = resnet18(weights=None)
        
        # ì…ë ¥ ì±„ë„ ë³€ê²½ (Luminance 1ì±„ë„)
        self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)
        
        # ìµœì¢… FC ë ˆì´ì–´ ë³€ê²½ (512 -> 25 weights)
        num_ftrs = self.resnet.fc.in_features
        self.resnet.fc = nn.Linear(num_ftrs, output_weights)
        
        # Differentiable TMO Layer
        self.tmo_layer = DifferentiableTMO(E_samples, f0_mean, H_basis)

    def forward(self, hdr_luminance_input, hdr_rgb_full):
        # 1. PCA Weights ì˜ˆì¸¡ (ResNet)
        weights_w = self.resnet(hdr_luminance_input) # [B, 25]
        
        # 2. CRF/TMO ì¬êµ¬ì„±
        sdr_output = self.tmo_layer(hdr_rgb_full, weights_w) # [B, 3, H, W]
        
        return sdr_output, weights_w

# ==============================================================================
# 3. ë°ì´í„°ì…‹ ë° ì „ì²˜ë¦¬ (ì‚¬ìš©ì íŒŒì¼ êµ¬ì¡° ë°˜ì˜)
# ==============================================================================

class HDRLDRDataset(Dataset):
    def __init__(self, hdr_dir, ldr_dir, target_size=(256, 256), full_size=(1024, 1024)):
        self.hdr_dir = hdr_dir
        self.ldr_dir = ldr_dir
        self.target_size = target_size
        self.full_size = full_size
        
        # HDR íŒŒì¼ ëª©ë¡ì—ì„œ ë²ˆí˜¸ ì¶”ì¶œ (e.g., '001', '002', ...)
        hdr_files = sorted(glob.glob(os.path.join(self.hdr_dir, 'HDR_*.hdr')))
        self.file_indices = [os.path.basename(f).split('_')[1].split('.')[0] for f in hdr_files]
        
        assert len(self.file_indices) > 0, f"ì˜¤ë¥˜: HDR ë””ë ‰í† ë¦¬ì—ì„œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œ: {hdr_dir}"
        print(f"ì´ {len(self.file_indices)} ìŒì˜ ì´ë¯¸ì§€ ì¸ë±ìŠ¤ ë¡œë“œ ì¤€ë¹„ ì™„ë£Œ.")


    def __len__(self):
        return len(self.file_indices)

    def __getitem__(self, idx):
        file_index = self.file_indices[idx]
        
        # ì‚¬ìš©ì êµ¬ì¡°ì— ë”°ë¥¸ íŒŒì¼ ê²½ë¡œ
        hdr_path = os.path.join(self.hdr_dir, f'HDR_{file_index}.hdr')
        ldr_path = os.path.join(self.ldr_dir, f'LDR_{file_index}.jpg') # LDR_exposure_0 í´ë” ë‚´ LDR_XXX.jpg
        
        # 1. ì›ë³¸ HDR ë¡œë“œ (1024x1024, float)
        hdr_rgb_full = iio.imread(hdr_path).astype(np.float32)
        # LDR Ground Truth ë¡œë“œ (0~1.0 float)
        ldr_gt_full = iio.imread(ldr_path).astype(np.float32) / 255.0
        
        # 2. ResNet ì…ë ¥ìš© HDR íœ˜ë„ ì „ì²˜ë¦¬
        # a) íœ˜ë„ ì¶”ì¶œ (Luminance)
        L_hdr_full = 0.2126 * hdr_rgb_full[..., 0] + 0.7152 * hdr_rgb_full[..., 1] + 0.0722 * hdr_rgb_full[..., 2]
        
        # b) ë‹¤ìš´ìƒ˜í”Œë§ (1024x1024 -> 256x256)
        # skimage.transform.resize ì‚¬ìš© (ê³ í’ˆì§ˆ ë¦¬ì‚¬ì´ì§•)
        L_hdr_downsampled = resize(L_hdr_full, self.target_size, 
                                   anti_aliasing=True, preserve_range=True).astype(np.float32)
        
        # c) ë¡œê·¸ ë³€í™˜ ë° ì •ê·œí™” (log(L+eps))
        L_hdr_input = np.log(L_hdr_downsampled + 1e-5)
        # ë°ì´í„°ì…‹ ì „ì²´ í‰ê· /í‘œì¤€í¸ì°¨ë¡œ ì •ê·œí™”í•˜ëŠ” ê²ƒì´ ì¢‹ìœ¼ë‚˜, ì—¬ê¸°ì„œëŠ” ì´ë¯¸ì§€ë³„ ì •ê·œí™” ì ìš©
        L_hdr_input = (L_hdr_input - L_hdr_input.mean()) / (L_hdr_input.std() + 1e-5)
        
        # Tensor ë³€í™˜
        L_hdr_input = torch.from_numpy(L_hdr_input).unsqueeze(0) # [1, H', W']
        hdr_rgb_full_tensor = torch.from_numpy(hdr_rgb_full).permute(2, 0, 1) # [3, H, W]
        ldr_gt_full_tensor = torch.from_numpy(ldr_gt_full).permute(2, 0, 1) # [3, H, W]
        
        return L_hdr_input.float(), hdr_rgb_full_tensor.float(), ldr_gt_full_tensor.float()


# ==============================================================================
# 4. í•™ìŠµ ì„¤ì • ë° ì‹¤í–‰
# ==============================================================================

# ğŸš¨ ì‚¬ìš©ì ì§€ì • í•„ìˆ˜ 1 ğŸš¨: LDR-HDR-pair_Dataset í´ë”ì˜ ìƒìœ„ ê²½ë¡œë¥¼ ì§€ì •í•´ì£¼ì„¸ìš”.
DATASET_ROOT = os.path.expanduser('~/TM/') 

# ğŸš¨ ì‚¬ìš©ì ì§€ì • í•„ìˆ˜ 2 ğŸš¨: EMoR ë°ì´í„° íŒŒì¼ì˜ ì ˆëŒ€ ê²½ë¡œë¥¼ ì§€ì •í•´ì£¼ì„¸ìš”.
# ì˜ˆì‹œ: EMOR_DATA_PATH = os.path.expanduser('/home/user/data/emorCurves.txt')
# í˜„ì¬ ì½”ë“œê°€ ìˆëŠ” ìœ„ì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìƒëŒ€ ê²½ë¡œë¥¼ ì¶”ì •í•˜ëŠ” ì½”ë“œì…ë‹ˆë‹¤.
EMOR_DATA_PATH = os.path.abspath(os.path.join(os.path.dirname(os.path.abspath(__file__)) if '__file__' in locals() else os.getcwd(), '../dataset/emorCurves.txt'))

def train_model():
    # ë°ì´í„° ê²½ë¡œ ìë™ êµ¬ì„±
    HDR_DIR = os.path.join(DATASET_ROOT, 'LDR-HDR-pair_Dataset', 'HDR')
    LDR_DIR = os.path.join(DATASET_ROOT, 'LDR-HDR-pair_Dataset', 'LDR_exposure_0') # ì‚¬ìš©ì êµ¬ì¡° ë°˜ì˜
    
    print(f"--- ë°ì´í„° ê²½ë¡œ í™•ì¸ ---")
    print(f"HDR ë””ë ‰í† ë¦¬: {HDR_DIR}")
    print(f"LDR ë””ë ‰í† ë¦¬: {LDR_DIR}")
    print(f"EMoR íŒŒì¼: {EMOR_DATA_PATH}")
    print(f"------------------------")
    
    # GPU ì„¤ì •
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ì‚¬ìš© ì¥ì¹˜: {device}")
    
    # 1. EMoR ë°ì´í„° ë¡œë“œ
    try:
        E_samples, f0_mean, H_basis = parse_emor_data(EMOR_DATA_PATH)
    except FileNotFoundError as e:
        print(f"\nFATAL ERROR: EMoR ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”: {e}")
        return
    
    E_samples, f0_mean, H_basis = E_samples.to(device), f0_mean.to(device), H_basis.to(device)
    print(f"EMoR ë°ì´í„° ë¡œë“œ ì™„ë£Œ. H_basis.shape: {H_basis.shape}")

    # 2. ëª¨ë¸ ì´ˆê¸°í™”
    model = ResNetEMoR(E_samples, f0_mean, H_basis).to(device)
    
    # 3. ë°ì´í„° ë¡œë”
    full_dataset = HDRLDRDataset(HDR_DIR, LDR_DIR)
    total_samples = len(full_dataset)
    train_size = int(0.8 * total_samples)
    val_size = total_samples - train_size
    train_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size])
    
    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=2)
    val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=2)
    
    print(f"ë°ì´í„°ì…‹ ë¶„í• : í•™ìŠµ {train_size}ê°œ, ê²€ì¦ {val_size}ê°œ")
    
    # 4. ì†ì‹¤ í•¨ìˆ˜ ë° ìµœì í™”
    criterion_recon = nn.L1Loss() 
    optimizer = optim.Adam(model.parameters(), lr=1e-5)
    lambda_reg = 1e-5 # PCA Weight L2 ì •ê·œí™” ê°€ì¤‘ì¹˜

    # 5. í•™ìŠµ ë£¨í”„
    num_epochs = 50
    for epoch in range(num_epochs):
        model.train()
        running_loss = 0.0
        
        for i, (L_hdr_input, hdr_rgb_full, ldr_gt_full) in enumerate(train_loader):
            L_hdr_input, hdr_rgb_full, ldr_gt_full = L_hdr_input.to(device), hdr_rgb_full.to(device), ldr_gt_full.to(device)
            
            optimizer.zero_grad()
            
            sdr_pred, weights_w = model(L_hdr_input, hdr_rgb_full)
            
            # L1 ì¬êµ¬ì„± ì†ì‹¤
            loss_recon = criterion_recon(sdr_pred, ldr_gt_full)
            
            # L2 Weight ì •ê·œí™” ì†ì‹¤
            loss_reg = torch.mean(weights_w.pow(2))
            
            loss = loss_recon + lambda_reg * loss_reg
            
            loss.backward()
            optimizer.step()
            
            running_loss += loss.item() * L_hdr_input.size(0)
            
        epoch_loss = running_loss / train_size
        print(f"Epoch {epoch+1}/{num_epochs}, Train Loss: {epoch_loss:.6f} (Recon: {loss_recon.item():.6f}, Reg: {loss_reg.item():.6f})")
        
        # 6. ê²€ì¦
        evaluate_model(model, val_loader, device, val_size)


# ==============================================================================
# 5. í‰ê°€ í•¨ìˆ˜ (TMQI Placeholder)
# ==============================================================================

def evaluate_model(model, val_loader, device, val_size):
    model.eval()
    val_loss = 0.0
    # TMQI PLACEHOLDER: tmqi_scoresëŠ” í˜„ì¬ ê³„ì‚°ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    
    with torch.no_grad():
        for L_hdr_input, hdr_rgb_full, ldr_gt_full in val_loader:
            L_hdr_input, hdr_rgb_full, ldr_gt_full = L_hdr_input.to(device), hdr_rgb_full.to(device), ldr_gt_full.to(device)
            
            sdr_pred, weights_w = model(L_hdr_input, hdr_rgb_full)
            
            loss_recon = nn.L1Loss()(sdr_pred, ldr_gt_full)
            val_loss += loss_recon.item() * L_hdr_input.size(0)
            
            # ------------------------------------------------------------------
            # TMQI ê³„ì‚° ë¡œì§ì´ ë“¤ì–´ê°ˆ ìë¦¬ (í˜„ì¬ëŠ” L1 Lossë§Œ ì¸¡ì •)
            # tmqi_score = calculate_tmqi(hdr_rgb_full, sdr_pred) 
            # ------------------------------------------------------------------

    avg_val_loss = val_loss / val_size
    print(f"  Validation L1 Loss: {avg_val_loss:.6f} (TMQI ë¯¸ì¸¡ì •)")
    
    model.train()

if __name__ == '__main__':
    train_model()